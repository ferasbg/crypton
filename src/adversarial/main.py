import sympy
import numpy
import scipy
import os, sys
import tensorflow as tf
import cleverhans

from nn.network import Network
from crypto.crypto_network import CryptoNetwork
from crypto.main import Crypto
from nn.metrics import Metrics


class Adversarial():
    perturbation_epsilon = 0.3 # perturbation epsilon is constant for each attack variant
    # track states for each adversarial attack, so in src.deploy.main we update this state if the static function is called 
    pgd_attack_state = False
    fgsm_attack_state = False
    norm_perturbation_attack_state = False
    # pixelwise_gaussian_noise_state = False

    @staticmethod
    def create_adversarial_example():
        '''General adversarial attack type that each perturbation type is nested in. I.e. every perturbation is the attempt to generate adversarial examples.'''
        # create adversarial example with perturbations to input_image iterating over entire train set to then pass into perturbed_train_generator
        raise NotImplementedError

    @staticmethod
    def setup_pixelwise_gaussian_noise(epsilon, input_image):
        # setup perturbation layer in network as adversarial defense/attack and perhaps use as utility function
        raise NotImplementedError

    @staticmethod
    def fgsm_attack(model_parameters, input_image, cost_function):
        """Fast-sign gradient method, denoted as Î· = sign (âˆ‡xJ(Î¸, x, y)). Generate adversarial examples to pass into network."""
        raise NotImplementedError

    @staticmethod
    def setup_fgsm_attack(input_image, input_image_label, perturbation_epsilon, model_parameters, loss):
        """Fast Gradient Signed Method (FGSM) attack as described in [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572) by Goodfellow *et al*. This was one of the first and most popular attacks to fool a neural network.

        Note, we will compute a pixelwise norm perturbation with respect to the proportionality of the pixel to its corresponding loss value, in order to maximize the loss, e.g. making it inaccurate. It is given that model is pretrained and the model parameters are constant.

        Formally denoted as Î·=Ïµ sign(âˆ‡â‚“ J(Î¸,x,y)).

        Args:
        -   x : Original input image.
        -   y : Original input label.
        -   $\epsilon$ : Multiplier to ensure the perturbations are small.
        -   $\theta$ : Model parameters.
        -   $J$ : Loss.

        Returns: adv_x e.g. adversarial image with perturbations with respect to adversarial optimization.

        References:
            - https://github.com/gongzhitaao/tensorflow-adversarial/blob/master/attacks/fast_gradient.py
            - https://neptune.ai/blog/adversarial-attacks-on-neural-networks-exploring-the-fast-gradient-sign-method
            - https://arxiv.org/pdf/1811.06492.pdf
            - https://deepai.org/publication/simultaneous-adversarial-training-learn-from-others-mistakes
        """
        perturbations = Adversarial.create_adversarial_pattern(input_image, input_image_label)
        for i in enumerate(1):
            adv_x = input_image + perturbation_epsilon*perturbations # matmul with perturbation epsilon
            adv_x = tf.clip_by_value(adv_x, -1, 1)
            i+=1

        return adv_x

    @staticmethod
    def create_adversarial_pattern(input_image, input_label):
        with tf.GradientTape() as tape:
            tape.watch(input_image) # map gradients
            prediction = (input_image) # given x to VGG-Net # rework model design
            loss_object = tf.keras.losses.CategoricalCrossentropy()
            loss = loss_object(input_label, prediction) # total error

        gradient = tape.gradient(loss, input_image)

        signed_grad = tf.sign(gradient)
        return signed_grad

    @staticmethod
    def setup_pgd_attack(loss, l_infinity_norm=0.2, l2_norm=2.0):
        raise NotImplementedError


    @staticmethod
    def projected_gradient_descent_attack(layer_gradient, network_gradients):
        # converge to max loss to create adversarial example
        # to get layer_gradient: tape.gradient(loss, linear_layer.trainable_weights)
        raise NotImplementedError

    @staticmethod
    def brightness_perturbation_norm(input_image):
        sigma = 0.085
        brightness_threshold = 1 - sigma
        input_image = tf.math.scalar_mul(brightness_threshold, input_image)
        return input_image
