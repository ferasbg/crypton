# `src.prediction`
The core deep convolutional neural network.


## Components
- `src.prediction.network`: network class
- `src.prediction.train`: train & evaluate network
- `src.prediction.abstract_network`: convert tf layers into abstract (bounded) layers to evaluate in `src.verification`


## RESEARCH AND FORMULATION
- An ML model can be viewed as a function mapping inputs – typically a vector of numerical feature values – to an output (a label for multiclass classification and a real number for regression). Focusing on multiclass classification, we define a model as a function f : R n → K that maps ndimensional inputs to a label in the set K = {1, . . . , K} of all possible labels. Such models typically map an input x to a vector of scores y(x) = (y1(x), . . . , yK(x)), such that yk(x) ∈ [0, 1] and PK k=1 yk(x) = 1. These scores are interpreted as a probability distribution over the labels, and the model returns the label with highest probability, i.e., f(x) = arg maxk∈K yk(x). ([https://arxiv.org/pdf/1802.03471.pdf](https://arxiv.org/pdf/1802.03471.pdf), *II.A*)
- Intuitively, a predictive model may be regarded as robust to adversarial examples if its output is insensitive to small changes to any plausible input that may be encountered in deployment. To formalize this notion, we must first establish what qualifies as a plausible input. This is difficult: the adversarial examples literature has not settled on such a definition. Instead, model robustness is typically assessed on inputs from a test set that are not used in model training – similar to how accuracy is assessed on a test set and not a property on all plausible inputs. We adopt this view of robustness. Next, given an input, we must establish a definition for insensitivity to small changes to the input. We say a model f is insensitive, or robust, to attacks of p-norm L on a given input x *if f(x) = f(x + α) for all α ∈ Bp(L). If f is a multiclass classification model based on label scores (as in §II-A), this is equivalent to: ∀α ∈ Bp(L)  yk(x + α) > max i:i6=k yi(x + α), (1) where k := f(x). A small change in the input does not alter the scores so much as to change the predicted label.*
- the public feed-forward neural network can be thought of as the composition of number of functions $f(x) = f_L(...f_2(f_1(x;w_1);w_2)...),w_L)$.
- Each function $f_l$ takes as input a datum **$x_l$** and a parameter vector $w_l$ and produces as output a datum $x_l+1$. The parameters, denoted as  $w = \{{w_1, ..., w_L}\}$, are learned from data in order to solve a target problem, in this case, classifying labels in an input image that denotes the input frame of data streamed from sensory input of an autonomous system for perception and for multi-label pixelwise classification in order to gauge motion-planning algorithms.
- The data $x_1, ..., x_n$ are images in general maps from a lattice to one or more real numbers. Given that the data itself is processed as an input matrix $M$ and the data is processed such that we evaluate it in terms of the subsets of the original image, in order to partition the input such that given local information and clustering can help to classify each pixel with respect to its neighboring pixels. This is done in order to make data processing efficient so that important components of the image that indicate objects can be detected and informed to a different vector stream (e.g. motion planning), for an autonomous system.
- Given each input image, say $x_i$, will be a $M x N x K$  real array of $M x N$ pixels and $K$ channels per pixel.
- The input image will undergo a series of transformations.
- The rectifier activation function, denoted as $y_{ijk} = max\{{0, x_{ijk}}\}$.
- In terms of region / search space, we would use the 3x3 receptive field, and apply the linear operator and filter to generate the set of feature maps which will then be iterated over with the kernel in the forwardpass to apply max pooling (removing greatest pixel in each 4-pixel subsubmatrix)
- The weight decay rate was $w$, the momentum was set to $0.9$, and the weight initialization was validated with the precedence property $p_n$ in order to maintain gradient stability during backpropagation, checking for null neuron activations and other inconsistencies of the network during its training process.
- We initialized the bias, as well as randomizing the weights of the network to then converge towards a local minima with backpropagation and gradient descent. The learning rate was constant throughout the training process.
- Given the input image matrix is greater than the fixed input `image_size` is `224x224`, other parts of the image will be sent as batches through automatic partitioning.
- We applied dropout regularization for the trainable fully-connected layers, and we applied batch normalization, data augmentation (random transformations with horizontal flipping, possibly to increase accuracy), in order to further apply nominal neural network optimization techniques.
- Another important CNN building block is channel-wise normalisation. This operator normalises the vector of feature channels at each spatial location in the input map x.
- We evaluate the state of the vector norm of each computation during the feedforward pass, and verifying the safety properties given the perturbed input and verifying the input-output state-transition relation.
- Given that the softmax operator is denoted as $y_{ijk'} = \frac{e^{x_{ijk'}}}{\sum_{k} e^{x_{ijk}}}$, and the log-loss is denoted as $y_{ij} = - \log x_{ij c_{ij}}$, where $c_{ij}$ is the index of the ground-truth class at spatial location $(i,j)$.

## Requirements
- compute the labels/annotations for each pixel for each input frame given a tensor (set of matrices of images), with metadata including `frame_number`, `num_cores`, `training_time`
- train model, then setup encrypted model that inherits base network from `prediction.network`, perform all operations necessary for training and testing, setup for formal specifications and encrypted training

## Research
- Logits are a probabilistic representation of the classification accuraccy of the model computed with softmax, generally can be symbolically represented with geoemtric abstraction
- Batch normalization for stablization of training network, max pooling for downsampling region of filter iterating over input frame matrix, by taking greatest value of each receptive field (of region / subset of matrix space of pixels), Dropout is meant to optimize model to avoid overfitting, which is where model stores useless generalizations
- Feature map is a representation of the mapping that corresponds to the tensor transformation in Hilbert Space. The map itself is not a representation of the signal but rather the representation of the transformation, the kernel and its learned parameters in their current state. Setup endpoints to track metrics for each timestep, for each updated state of the variables corresponding to the learning of the network.
- The kernel is a matrix that acts a factor for matrix multiplication with input channel, which is a matrix computed from a receptive field, to which there is a set of receptive fields or submatrices that make up a Tensor. The dimensions also define the rank of the representation.
- Important to setup reachable states at different time steps, will just iterate over all sequential computations, and at each timestep, I will call the specification functions to access required object state data to determine if it violates robustness, safety, and liveness properties defined. Now given that the model will just be trained on self-driving data where it's required to map each frame or environment state to maintain trained behavior (to correctly detect and segment input data, we are not concerned with any policy enforcement for control and motion / planning, and only with the perception module in this work)
- To formalize the problem, it is a reachability problem in that we need to make formal and correct abstractions of a combinatorially large state space, and then use symbolic interval analysis and signal temporal logic.
- Given the cryptographic property of an smpc scheme to train and test the model privately, how can we securely and correctly formalize and provide safety and robustness guarantees of our neural network?
- We will be concerned with a subspace or subset of variables or signals relating to the object's state, the object more specifically is the neural network, to which it can extend to maintain / guarantee security and privacy policies / properties.
- We also have to define and upper and lower bound, AND need to understand where it is necessary to access and compute the probabilistic violation of a security, safety, robustness, and liveness property, and collect metrics.
- Defining function to compute upper and lower bounds over values of the function, and that the function itself is Lipschitz continous, which is where for every pair, the absolute value of the slope of the line connecting them is not greater than the real number (the derivative of any point of the function)
- We also need to define a set of properties, and also define a set of arguments necessary to then access from the `src.prediction.nn` 
- Note that ground truth refers to each pixel in a 224x224 image being labeled (multi-label classification) with a state-value. It is a mapping technique for information specific to each 224x224 input frame.
- The key correctness problems can be divided as such: adversarial examples, safety verification, output range analysis, and robustness comparison.
- Past work has been focused on modeling the problem in a reductionist approach, and a boolean satisfiability or probabilistic satisfiability for 0 < k < n, or either it passes properties or not instead of being a distribution of points (indicating metrics regarding its Tensor states) with upper and lower bounds and distance from correctness. 
- During pre-processing, important to initialize weights, and other variables specific to the Tensor object. So the problem also occurs when there's billions of different humans or obstacles, and that in runtime, the abstraction or problem formulation has to be such that there's no lost translation but also that it meets computational constraints.
- A translation relation is a concept in model checking where
- Important to understand signal sets (variables)
- Note complexity in classification comes from the diversity of objects, their variants, the environmental conditions, and the randomness and perturbations to the visual perception that can distort the classification itself. Every input_image processed is assumed to have been segmented for each image to be evaluated with respect to its location.


