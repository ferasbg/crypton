# Federated Adversarial Robustness Verification for Deep Convolutional Neural Networks
The purpose of this work is to build a system that can formally verify the safety and robustness properties of a federated deep convolutional neural network (FDCNN), using a bounded model checking technique specifically designed for compositional-semantic abstraction and dual optimization.
