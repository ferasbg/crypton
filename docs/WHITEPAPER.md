# Crypton: Formal Verification for Privacy-Preserving Deep Convolutional Neural Networks

## Abstract
The purpose of this work is to build a system to formally verify the safety and robustness properties of a deep convolutional neural network for semantic image segmentation with signal temporal logic specifications and reachability analysis in a privacy-preserving, zero-trust approach with respect to computational efficiency.

## Introduction
The end goal is to setup STL specifications and run them and return statistical significance given relevant input-output relationships. Additionally, the optimal goal is to have similar performance with other networks, and to actually train instances of the network in parallelization if necessary. But the goal is to formally guarantee safety properties of the network under a privacy-preserving, zero-trust environment for the neural network.

## Problem Formulation



## Framework
- import workflow of technical implementation in terms of system components, how training and testing was executed in terms of the network


## Safety Verification


## Signal Temporal Logic


## Secure Multi-Party Computation for Secure Network Training 


## Evaluation


## Conclusion
- multi-agent, distributed, parallelization of verified ensemble networks for end-to-end autonomous system in zero-trust multi-agent environments

